

# Deep Learning

## Introduction to Deep Learning in Python  (Datacamp)

### Intro
3 layers:
* input layer
* hidden layer
* output layer

### Forward Propagation
- Forward propagation refers to the calculation and storage of intermediate variables (including outputs) for a neural network in order from the input layer to the output layer.
- from input layer to output layer (left to right)
- each connectin has a weight
- from input layer to hidden layer
  - each node in hidden layer is a sum of the inputs multiplied by the weights
  - each node in hidden layer has an activation function


### Activation Functions
linear vs. non-linear activation functions

#### ReLu (Rectified Linear Activation)




